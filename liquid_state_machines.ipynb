{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Ls6qeh92w4y1"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "class LiquidStateMachine(nn.Module):\n",
        "    def __init__(self, input_size, reservoir_size, output_size):\n",
        "        super(LiquidStateMachine, self).__init__()\n",
        "\n",
        "        self.input_size = input_size\n",
        "        self.reservoir_size = reservoir_size\n",
        "        self.output_size = output_size\n",
        "\n",
        "        self.input_weights = nn.Parameter(torch.FloatTensor(self.reservoir_size, self.input_size))\n",
        "        self.reservoir_weights = nn.Parameter(torch.FloatTensor(self.reservoir_size, self.reservoir_size))\n",
        "        self.output_weights = nn.Parameter(torch.FloatTensor(self.output_size, self.reservoir_size))\n",
        "\n",
        "        self.tanh = nn.Tanh()\n",
        "\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        #want to initialize to this so we can make sure our weights start in a tanh-like way\n",
        "        nn.init.xavier_uniform_(self.input_weights)\n",
        "        nn.init.xavier_uniform_(self.reservoir_weights)\n",
        "        nn.init.xavier_uniform_(self.output_weights)\n",
        "\n",
        "    def forward(self, input_data):\n",
        "        reservoir_state = torch.zeros((self.reservoir_size, 1), dtype=torch.float32)\n",
        "\n",
        "        for input_sample in input_data:\n",
        "            input_sample = input_sample.view(-1, 1) # reshape from [sequence_length,] to [sequence_length, 1]\n",
        "            reservoir_state = self.tanh(\n",
        "              torch.matmul(self.input_weights, input_sample) +\n",
        "              torch.matmul(self.reservoir_weights, reservoir_state))\n",
        "\n",
        "        output = torch.matmul(self.output_weights, reservoir_state)\n",
        "        return output.squeeze()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_mackey_glass(T, beta=0.2, gamma=0.1, n=0.1, tau=17):\n",
        "    x = np.zeros(T)\n",
        "    x[0] = 1.5\n",
        "\n",
        "    for t in range(T - 1):\n",
        "        x[t + 1] = x[t] + (beta * x[t - tau]) / (1 + x[t - tau]**10) - gamma * x[t]\n",
        "        x[t + 1] *= (1 - n)\n",
        "\n",
        "    return x\n",
        "\n",
        "T = 2000\n",
        "mackey_glass_data = generate_mackey_glass(T)"
      ],
      "metadata": {
        "id": "djwbeybfybPE"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#No strong need to save and load, just wanted to practice it\n",
        "np.savetxt('mackey_glass.csv', mackey_glass_data, delimiter=',')\n",
        "data = np.loadtxt('mackey_glass.csv', delimiter=',')"
      ],
      "metadata": {
        "id": "rTZTK-1FlWfV"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequence_length = 10\n",
        "input_data = np.array([data[i:i+sequence_length] for i in range(len(data)-sequence_length)])\n",
        "target_data = data[sequence_length:]"
      ],
      "metadata": {
        "id": "lj6YBIvPlX06"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_data = (input_data - np.mean(input_data)) / np.std(input_data)\n",
        "\n",
        "input_train, input_test, target_train, target_test = train_test_split(input_data, target_data, test_size=0.2, shuffle=False)"
      ],
      "metadata": {
        "id": "pcfLI0ztlepY"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_train = torch.from_numpy(input_train).float()\n",
        "input_test = torch.from_numpy(input_test).float()\n",
        "target_train = torch.from_numpy(target_train).float()\n",
        "target_test = torch.from_numpy(target_test).float()"
      ],
      "metadata": {
        "id": "VJ9naia7liPq"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = sequence_length\n",
        "reservoir_size = 100\n",
        "output_size = 1\n",
        "learning_rate = 0.001\n",
        "num_epochs = 100"
      ],
      "metadata": {
        "id": "Ewf-wq6wljie"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LiquidStateMachine(input_size, reservoir_size, output_size)"
      ],
      "metadata": {
        "id": "5McKUORVlmBA"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "i_P870yHlnQM"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "    output_train = model(input_train)\n",
        "    loss = criterion(output_train, target_train)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (epoch+1) % 10 == 0:\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ChYKvSKglo9G",
        "outputId": "7ba96dbd-d728-4590-b349-c6cc5002ff4e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([1592])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/100], Loss: 0.0427\n",
            "Epoch [20/100], Loss: 0.0113\n",
            "Epoch [30/100], Loss: 0.0073\n",
            "Epoch [40/100], Loss: 0.0040\n",
            "Epoch [50/100], Loss: 0.0035\n",
            "Epoch [60/100], Loss: 0.0034\n",
            "Epoch [70/100], Loss: 0.0031\n",
            "Epoch [80/100], Loss: 0.0031\n",
            "Epoch [90/100], Loss: 0.0031\n",
            "Epoch [100/100], Loss: 0.0031\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    output_test = model(input_test)\n",
        "    test_loss = criterion(output_test, target_test)\n",
        "    print(f'Test Loss: {test_loss.item():.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BkKR9ic5lSHE",
        "outputId": "a9f513eb-3e95-46a9-cf3c-d4a0ddf164c9"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.0023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([398])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        }
      ]
    }
  ]
}